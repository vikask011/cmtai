ğŸ§  BeyondChats Article Intelligence Platform

A full-stack Node.js + React application that scrapes blog articles, enriches them using Google Search results and Gemini LLM, and visualizes original vs updated content in a clean UI.

This project demonstrates web scraping, REST APIs, LLM integration, and frontend rendering in a production-style workflow.

ğŸš€ Features
ğŸ”¹ Backend (Node.js + Express + MongoDB)

Scrape articles from BeyondChats blog

Store articles in MongoDB

Full CRUD REST API

Enrich articles using:

Google Search (SerpAPI)

Gemini LLM (content rewriting)

Track article status (original / updated)

Store reference links used for enrichment

ğŸ”¹ Frontend (React + Tailwind CSS)

Clean, centered article feed

Visual distinction between:

Original articles

Gemini-updated articles

Reference links displayed for updated articles

Responsive, modern UI

Loading state handling

ğŸ§© System Architecture
Scraper â”€â”€â–¶ MongoDB â”€â”€â–¶ Express API â”€â”€â–¶ React UI
                    â–²
                    â”‚
        Google Search + Gemini LLM

ğŸ›  Tech Stack
Backend

Node.js

Express.js

MongoDB + Mongoose

Axios

Cheerio

SerpAPI

Google Gemini API

Frontend

React (Vite)

Tailwind CSS

Axios

ğŸ“ Project Structure
project-root/
â”‚
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ server.js
â”‚   â”œâ”€â”€ db.js
â”‚   â”œâ”€â”€ Article.js
â”‚   â”œâ”€â”€ scraper.js
â”‚   â””â”€â”€ scripts/
â”‚       â””â”€â”€ updateArticles.js
â”‚
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”‚   â””â”€â”€ ArticleCard.jsx
â”‚   â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”‚   â””â”€â”€ api.js
â”‚   â”‚   â”œâ”€â”€ App.jsx
â”‚   â”‚   â”œâ”€â”€ main.jsx
â”‚   â”‚   â””â”€â”€ index.css
â”‚   â””â”€â”€ vite.config.js
â”‚
â””â”€â”€ README.md

ğŸ” Environment Variables

Create a .env file inside backend/:

MONGO_URI=mongodb+srv://<username>:<password>@cluster.mongodb.net/scraping
SERPAPI_KEY=your_serpapi_key
GOOGLE_API_KEY=your_gemini_api_key

â–¶ï¸ How to Run the Project
1ï¸âƒ£ Backend Setup
cd backend
npm install
node server.js


Server runs on:

http://localhost:5000

2ï¸âƒ£ Scrape Initial Articles
node scraper.js


This will:

Scrape BeyondChats blogs

Save articles to MongoDB

3ï¸âƒ£ Enrich Articles Using Gemini
node scripts/updateArticles.js


This script:

Searches article titles on Google

Scrapes top ranking articles

Uses Gemini to rewrite content

Updates the article via REST API

Adds reference links

4ï¸âƒ£ Frontend Setup
cd frontend
npm install
npm run dev


Frontend runs on:

http://localhost:5173

ğŸ”Œ REST API Endpoints
Method	Endpoint	Description
GET	/articles	Fetch all articles
GET	/articles/:id	Fetch single article
POST	/articles	Create article
PUT	/articles/:id	Update article
DELETE	/articles/:id	Delete article
ğŸ¤– Why Google Search + Gemini?

Google Search ensures reference articles are:

Real

Recent

Ranking highly

Gemini LLM:

Rewrites content to match high-ranking article style

Improves structure and readability

Result:

Human-readable, SEO-aligned content

Transparent citations at the bottom

ğŸ§  Key Learning Outcomes

Web scraping with Cheerio

API-driven architecture

LLM integration using REST APIs

Handling rate limits and blocked domains

Clean React component architecture

Tailwind-based responsive layouts

âš ï¸ Notes

Some websites block scraping (e.g. Medium, Reddit)

Blocked domains are safely skipped

Gemini output is validated before saving

References are always cited
